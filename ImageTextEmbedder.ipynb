{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install open-clip-torch faiss-cpu --quiet"
      ],
      "metadata": {
        "id": "oVPUAUKlU6JV"
      },
      "id": "oVPUAUKlU6JV",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1IKEKtMViwX",
        "outputId": "1fadfeb2-ae36-4c96-85aa-9064b05b5ce3"
      },
      "id": "M1IKEKtMViwX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl --quiet"
      ],
      "metadata": {
        "id": "AWH1tHUTYgkz"
      },
      "id": "AWH1tHUTYgkz",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÇ STEP 3: Set up paths and import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import open_clip\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "6AEloliUVm-r"
      },
      "id": "6AEloliUVm-r",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
        "model = model.to(device)\n",
        "tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duU2L13AWgvf",
        "outputId": "b0c43d86-6a72-4da3-a316-79d3cead712c"
      },
      "id": "duU2L13AWgvf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/open_clip/factory.py:388: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products_df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/product_data.xlsx\")\n"
      ],
      "metadata": {
        "id": "ZkOkiTL_W9TT"
      },
      "id": "ZkOkiTL_W9TT",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/images.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/images\"\n"
      ],
      "metadata": {
        "id": "GvelkRULcKU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e5a1c6-3b23-428e-95cf-3a16013722ef"
      },
      "id": "GvelkRULcKU4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/drive/MyDrive/Colab Notebooks/images/images/116103_11358.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace /content/drive/MyDrive/Colab Notebooks/images/images/116103_11359.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: none\n",
            "replace /content/drive/MyDrive/Colab Notebooks/images/images/116103_11360.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/Colab Notebooks/images/images\""
      ],
      "metadata": {
        "id": "n-9TzbOLVmfq"
      },
      "id": "n-9TzbOLVmfq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_text(row):\n",
        "    parts = []\n",
        "    for col in row.index:\n",
        "        value = row[col]\n",
        "        if pd.notnull(value):\n",
        "            parts.append(f\"{col}: {value}\")\n",
        "    return \" \".join(parts)\n"
      ],
      "metadata": {
        "id": "n8UF0Oy9o_Bc"
      },
      "id": "n8UF0Oy9o_Bc",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Map base IDs to image filenames\n",
        "available_images = {}\n",
        "for f in os.listdir(image_dir):\n",
        "    if f.endswith(\".jpg\"):\n",
        "        base_id = f.split(\"_\")[0]  # Extract the ID before underscore\n",
        "        if base_id not in available_images:\n",
        "            available_images[base_id] = f  # Only keep the first match\n",
        "\n",
        "# # Embed\n",
        "# embeddings = []\n",
        "# meta_data = []\n",
        "\n",
        "# print(\"üîÅ Generating embeddings from local images...\")\n",
        "\n",
        "# for idx, row in tqdm(products_df.iterrows(), total=len(products_df)):\n",
        "#     product_id = str(row[\"id\"])\n",
        "\n",
        "#     matching_file = available_images.get(product_id)\n",
        "#     if not matching_file:\n",
        "#         continue\n",
        "\n",
        "#     try:\n",
        "#         image_path = os.path.join(image_dir, matching_file)\n",
        "#         image = Image.open(image_path).convert(\"RGB\")\n",
        "#         image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "#         text = f\"{row['title']} {row.get('category', '')}\"\n",
        "#         text_input = tokenizer(text).unsqueeze(0).to(device)\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             image_feat = model.encode_image(image_input)\n",
        "#             text_feat = model.encode_text(text_input)\n",
        "#             combined = (image_feat + text_feat) / 2\n",
        "#             combined = combined / combined.norm(dim=-1, keepdim=True)\n",
        "\n",
        "#         embeddings.append(combined.cpu().squeeze().numpy())\n",
        "#         meta_data.append(row.to_dict())\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Failed to process ID {row['id']}: {e}\")\n",
        "# Embed only products that have a corresponding image\n",
        "embeddings = []\n",
        "meta_data = []\n",
        "\n",
        "for idx, row in tqdm(products_df.iterrows(), total=len(products_df)):\n",
        "    try:\n",
        "        product_id = str(row[\"id\"])\n",
        "        matching_file = available_images.get(product_id)\n",
        "\n",
        "        if not matching_file:\n",
        "            continue  # Skip if image is not available\n",
        "\n",
        "        # Combine all row fields into a single text\n",
        "        text = row_to_text(row)\n",
        "\n",
        "        # Load image\n",
        "        image_path = os.path.join(image_dir, matching_file)\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_input = preprocess(image).unsqueeze(0).to(device)  # [1, 3, H, W]\n",
        "\n",
        "        # Tokenize text (DO NOT UNSQUEEZE)\n",
        "        text_input = tokenizer(text).to(device)  # already [1, seq_len]\n",
        "\n",
        "        # Encode both\n",
        "        with torch.no_grad():\n",
        "            image_feat = model.encode_image(image_input)\n",
        "            text_feat = model.encode_text(text_input)\n",
        "\n",
        "            combined = (image_feat + text_feat) / 2\n",
        "            combined = combined / combined.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        embeddings.append(combined.cpu().squeeze().numpy())\n",
        "        meta_data.append(row.to_dict())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to process ID {row['id']}: {e}\")\n"
      ],
      "metadata": {
        "id": "Dz1KTYi0ZTTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab1a136-43fa-4c89-8919-baccd4e349de"
      },
      "id": "Dz1KTYi0ZTTG",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 969/969 [02:23<00:00,  6.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total successful embeddings: {len(embeddings)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxP1TodJZvaD",
        "outputId": "dcb13f13-c495-4e9f-c6be-ed3759198617"
      },
      "id": "VxP1TodJZvaD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total successful embeddings: 967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d50d415a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "d50d415a",
        "outputId": "e30012de-8b0d-42ba-b55d-9662a767f069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Embedded and saved FAISS index for 967 products.\n",
            "üì¶ Zipped faiss_output.zip and ready for download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b464b8f-a0dc-41ce-95c8-5270061e7af0\", \"faiss_output.zip\", 128242)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Save FAISS index\n",
        "embedding_matrix = np.vstack(embeddings).astype(\"float32\")\n",
        "index = faiss.IndexFlatIP(embedding_matrix.shape[1])\n",
        "os.makedirs(\"utils\", exist_ok=True)\n",
        "faiss.write_index(index, \"utils/faiss_catalog.index\")\n",
        "with open(\"utils/catalog_meta.pkl\", \"wb\") as f:\n",
        "    pickle.dump(meta_data, f)\n",
        "\n",
        "print(f\"\\n‚úÖ Embedded and saved FAISS index for {len(meta_data)} products.\")\n",
        "\n",
        "# üéÅ Zip FAISS output for download\n",
        "import shutil\n",
        "shutil.make_archive(\"faiss_output\", 'zip', \"utils\")\n",
        "print(\"üì¶ Zipped faiss_output.zip and ready for download.\")\n",
        "\n",
        "# ‚¨áÔ∏è Download result from Colab\n",
        "from google.colab import files\n",
        "files.download(\"faiss_output.zip\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}